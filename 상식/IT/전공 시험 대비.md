# 전공 시험 대비

[TOC]

## Network

### Nagle Algorithm

> 가능하면 조금씩 여러번 보내지 말고 한번에 많이 보내라(Effective TCP)

 전송해야할 데이터가 있는데, 상대방의 윈도우 크기가 매우 작은 경우, 내가 의도하진 않았짐나 보낼 수 있는 세그먼트의 크기 자체가 작기 때문에 따로 지연 설정을 하지 않으면, 작은 크기의 세그먼트가 만들어질 수밖에 없다. 보낼 수 있는 데이터를 바로 세그먼트로 만들지 않고, 가능한 모아서 더 큰 세그먼트로 만들어 한번에 보내면 이런 문제는 발생하지 않을 것이다. 네이글 알고리즘은 이 대안을 실제로 구현한 네트워크 전송 알고리즘이다.

  Segment의 최대 크기는 1460byte이다. 이것을 꽉 채워서 보내는게 좋을텐데 어떻게 하면 그럴 수 있을까. 알고리즘은 다음과 같다

- 처음에 데이터가 들어오면 데이터 크기와 상관없이 일단 보낸다.
- 두번째부터는
  - ACK가 도착했을 경우, 쌓인 데이터를 보낸다.
  - Segment 크기만큼 데이터가 쌓일 경우, 데이터를 보낸다.
- 두번째를 계속 반복한다.

### TCP Connection

  3-way handshake. 즉 세그먼트가 세 번 교환됨으로써 커넥션이 이루어진다. 2-way로 하면 왜 안될까.  클라이언트가 연결하자고 요청하면 서버가 대답하는 것이 2-way일 것인데, 서버의 대답이 도착한다는 보장이 없다. 

#### 3-way handshake

![three way handshake에 대한 이미지 검색결과](https://learningnetwork.cisco.com/resources/statics/1219267/av440f1_transport_p1_q2_poster.jpg)

 처음에 클라이언트가 SYN bit를 1로해서 보낸다. 서버가 tcp connection할 의향이 있으면 응답을 보낸다. SYNACK SYN bit이 1이면서 ACK를 보낸다. 그러면 다시 클라이언트는 받아서 ACK를 보낸다.

#### termination

![four way handshake에 대한 이미지 검색결과](https://t1.daumcdn.net/cfile/tistory/2336285058D7288E33)

 클라이언트가 더 이상 보낼 것이 없는 경우, FIN bit을 1로 보낸다. 서버는 ack를 보내고 난 후, 서버가 보내야 할 데이터 다 보낸 후에 FIN  bit을 1로 보낸다. 클라이언트도 여기에 대해서 ack를 보낸다. 클라이언트는 보내고 마지막 ack를 보낸 후 바로 끝나는 것이 아니라 아직 연결상태를 기다려야 한다. 마지막 FIN에 대한 ack가 유실될 경우를 대비해서. 

### Subnet Mask

#### Subnet이란

IP 주소는 Network ID, Host ID로 나뉜다. Network id를 Subnet이라고 부르기도 한다. 그래서 Ip는 subnet 파트, host 파트로 나뉜다. Subnet은 어떤 디바이스의 집합니다. 공통된 서브넷 주소를 가지고 있는 디바이스의 집합. 같은 서브넷에 존재하는 디바이스끼리는 라우터를 거칠 필요가 없다. 다른 서브넷에 있는 디바이스에 접근하기 위해서는 라우터를 거쳐야 한다. 서브넷은 물리적으로 라우터로 나뉘어 있다. 라우터는 특수한 디바이스이다. 호스트는 하나의 서브넷에 속해있지만 라우터는 여러 개의 서브넷에 속해있다. 그래서 자신이 속한 서브넷을 포워딩하는 역할을 한다.

![1569997667245](C:\Users\multicampus\AppData\Roaming\Typora\typora-user-images\1569997667245.png)

 여기서 서브넷은 총 6개이다. 라우터의 개수만큼 서브넷을 건너야 한다.

#### Subnet Mask

 IP주소가 있으면 서브넷 부분만 1로 만든다. xxx.xxx.xxx.xxx / 24 인 경우, 서브넷마스크는 11111111 11111111 11111111 00000000 이 된다. 그래서 IP주소와 and 연산하여 서브넷 부분만 쏙 빼내어 forwarding table과 비교한다.

### OSI 7 Layer : 물데네전세표응

하위계층 : 물리 -> 데이터링크 -> 네트워크
상위계층 : 전송 -> 세션 -> 표현 -> 응용

#### Physical Layer

 시스템의 전기적, 물리적 표현을 나타낸다. 케이블 종류, 무선 주파수 링크는 물론 핀 배치, 전압, 물리 요건 등이 포함된다. 네트워킹 문제가 발생하면 많은 네트워크 전문가가 물리 계층으로 바로 가서 모든 케이블이 제대로 연결돼 있는지, 라우터나 스위치 또는 컴퓨터에서 전원 플러그가 빠지지 않았는지 확인한다. 

 사용되는 통신 단위는 비트이며 이것은 1, 0의 전기적 신호로 나타낸다. 단지 데이터를 전기적인 신호로 변환해서 주고받는 기능만 할 뿐이다. 대표적으로는 통신 케이블, 리피터, 허브 등이 있다.

##### 리피터

 근접한 2개 이상의 데이터 네트워크간 신호를 전송하며 리피터는 신호를 재생하고 복사하는 장비이다. 데이터가 전송되는 동안 케이블에서는 신호의 손실인 감쇄 현상이 일어나는데 리피터는 감쇄되는 신호를 증폭하고 재생하여 전송하는 역할을 한다. IP주소나 MAC 주소를 이해하지 못한다.

##### 허브

 전기적인 신호를 증폭시켜 LAN의 전송거리를 연장시키고 여러대의 장비를 LAN에 접속할 수 있도록 한다. UTP 케이블을 사용하는 환경에서 장비들을 상호 연결시키는 콘센트레이터 역할도 함께 제공한다. 한 장비에서 전송된 데이터 프레임을 허브로 연결된 모든 장비에게 다 전송하는 플러딩이 발생한다.

#### Data Link Layer

 데이터 링크 계층은 두 개의 직접 연결된 노드 사이의 노드간 데이터 전송을 제공하며 물리 계층의 오류 수정도 처리한다. 2개의 부계층이 존재하는데 하나는 매체 접근 제어(MAC) 계층이고 다른 하나는 논리적 연결 제어(LLC) 계층이다. 네트워킹 세계에서 대부분 스위치는 2계층에서 작동한다.

##### 프레이밍

 데이터를 프레임으로 그룹화하여 전송한다. 데이터 배열에 Data, Header, Trailer 등을 넣어 캡슐화하는 작업이다. 각 노드에서 다음 노드로 데이터를 보낼 때, 네트워크 레이어에서 받은 데이터그램을 캡슐화하는 작업이다. 그리고 캡슐화된 틀(데이터배열)을 프레임이라고 한다.

##### 흐름제어

 송신자와 수신자의 처리 속도 차이를 해결하기 위한 제어. 송신 측이 수신 측 데이터 처리 속도보다 훨씬 빠른 속도로 데이터를 보내면 수신 측의 버퍼가 점점 길어질 것이다. 이를 방지하기 위해 수신 측에서 송신 측에게 그만 보내거나 천천히 보내라는 피드백을 보낼 수 있는데, 이것을 흐름제어라고 한다.

##### 에러제어

 송신 측에서 Framing을 하고 이것을 0과 1로 이루어진 비트로 변환하고 보낸다. 수신 측에서 당연히 이 비트 배열을 받을텐데, 0과 1로 이루어진 전기적 신호들이 매우 취약하기 때문에 수신 측의 데이터 링크 계층에서 에러를 감지하는 역할을 한다. 두 가지 방법이 있다. 1) 에러를 직접 수정(해밍코드) 2) Frame 폐기 후 재송신 요청.

##### 순서제어

 패킷이나 ACK 신호를 잘못 혼동하는 것을 피하기 위해 패킷과 ACK 신호 안에 Sequence number가 부여되어야 한다. 이것으로 순서제어 ㄱㄱ.

##### ARP(Address Resolution Protocol)

 우리는 IP주소를 통해 인터넷 상 본인의 정확한 위치를 알려줄 수 있다. 그러나 일반적으로 송신자와 수신자가 직접 연결된 것이 아니라 라우터와 서버로 연결되어 있다. 중간에 거쳐야할 정거장이 많다. 그래서 라우터를 통해 데이터를 보내주어야 한다. 

 전기적 신호는 IP가 아닌 MAC 주소를 따라 흐른다. 수신측으로 향하는 길의 중간에 있는 노드들의 MAC 주소가 필요하다. 이 때 유용한 기술이 ARP이다. ARP는 네트워크 상에서 IP주소를 MAC 주소로 대응(bind)시키기 위해 사용되는 프로토콜이다.

같은 네트워크 망일 경우,
 송신자는 수신자의 MAC주소가 알고싶다. 그러나 송신자가 알고있는 것은 IP주소밖에 없다. 그래서 송신자는 Broadcast Address를 이용해서 모든 노드에게 특정 IP주소를 가지고 있는 노도는 MAC 주소를 송신자 측에게 보내라고 한 것이다. 그러면 특정 IP주소를 가지고 있는 노드는 MAC주소를 전송하고 서로 IP주소와 MAC 주소를 알 수 있게 된다. MAC 주소는 직접 연결된 범위(스위치, 허브, 라우터 등)에서만 사용할 수 있다.

다른 네트워크 망일 경우,
 송신자는 수신자가 자신의 대역과 다르다는 것을 알았다. 송신자는 라우터의 MAC 주소를 알아내어 Default Gateway로 지정한다. 그리고 라우터에게 수신자와 통신하고 싶다고 말한다. 그리고 보낼 데이터를 라우터에 보내면 된다. 송신자가 수신자와 통신하기 위해 수신자의 MAC 주소를 알 필요가 없게 된다. Default Gateway는 라우팅을 통해 송신자에게 패킷을 보낸다. 출발지 IP는 송신자이지만 출발지 MAC주소는 Default Gateway MAC 주소이다. 송신자 측의 네트워크에 패킷이 도착하면 ARP를 통해 D의 MAC주소를 알아낸 뒤 송신자에게 패킷을 전달한다.[^1]

#### Network Layer

 이 계층에서 가장 중요한 기능은 데이터를 목적지까지 가장 안전하고 빠르게 전달하는 기능(라우팅)이다. 여기에 사용되는 프로토콜의 종류도 다양하고, 라우팅하는 기술도 다양하다. 이 계층은 경로를 선택하고 주소를 정하고 경로에 따라 패킷을 전달해주는 역할을 한다. 대표적인 장비는 라우터이며 2계층의 스위치에 라우팅 기능을 장착한 L3 스위치도 있다.

 라우팅, 흐름제어, 세그멘테이션, 오류제어, 인터네트워킹 등을 수행한다.

#### Transport Layer

#### Session Layer

  상위 계층에 제공하는 서비스로 세션 연결 설정과 해제, 세션 메시지 전송을 통해 동작한다. 크게 동기기능과 대화 기능을 수행한다. 2대의 기기, 컴퓨터 또는 서버 간에 대화가 필요하면 세션을 만들어야 하는데 이 작업이 여기서 처리된다.[^2]

##### 동기기능

 통신 양단끼리 서로 동의하는 논리적인 공통 시점인 동기점을 만들어 메시지가 제대로 처리되고 있는지 파악한다. 동기점은 오류 복구를 위하여 필수적으로 사용되는데 동기점 설정 이전까지는 서로 처리가 완료되었음을 합의하는 역할을 한다. 동기점 이전까지는 복구할 필요가 없고, 동기점 이후 처리 과정에 대한 복구 절차가 진행된다. 

##### 대화기능

 대화는 데이터 전송 과정을 의미한다. 시간 경과에 따라 순차적으로 동기점을 부여하여 신뢰성 보장 기능을 단계적으로 구현할 수 있게 된다. 대화를 관리하기 위해 토큰이라는 특수 메시지를 사용한다. 토큰을 가지고 있다는 것은 해당 토큰에 부여된 특정 권리를 배타적으로 소유한다는 의미를 가진다. 권한으로는 데이터를 전송할 수 있는 권한, 통신 양단 사이 연결을 해제하는 권한 등이 있다.

 큰 파일 전체를 하나의 단위로 전송하는 것보다 논리적으로 작은 단위로 나누어서 전송하는 것이 오류 발생 시 유리하다. 오류가 발생하면 오류가 난 부분부터 다시 보내면 되기 때문이다. 그래서 동기점이 중요하다. 

#### Presentation Layer

 응용 계층의 데이터 표현에서 독립적인 부분을 나타낸다. 응용프로그램 형식을 준비 또는 네트워크 형식으로 변환하거나 네트워크 형식을 응용프로그램 형식으로 변환하는 것을 나타낸다. 응용프로그램이나 네트워크를 위해 데이터를 표현하는 것이다. 대표적인 예로 데이터 암호화, 복호화 등이 있다.

#### Application Layer

 사용자에게 보이는 부분이다. 응용프로그램은 사용자와 직접적으로 상호작용한다. 브라우저와 응용 프로그램이 대표적인 예이다. HTTP, FTP, SMTP, TELNET 등과 같은 프로토콜이 있다.

### Parity Bit

![img](https://mblogthumb-phinf.pstatic.net/MjAxNjEyMTVfNDgg/MDAxNDgxNzc4Mjg0NTk2.Ln8Hqrvkg1KjguXpEf9ISN9Cqijkg7rnvu0JUjMJ4Dwg.HCbNEziV16sQvFmbRAPsVzZrvYCQqtV6H6QjYuqFP70g.PNG.ansdbtls4067/%EA%B7%B8%EB%A6%BC5.png?type=w800)

#### Even Parity(짝수 패리티)

 짝수 패리티는 실제 송신하고자 하는 데이터의 각 비트의 값 중에서 1의 개수가 짝수가 되도록 패리티 비트를 정하는 것이다. 데이터 비트에서 1의 개수가 짝수이면 1로 정하고 짝수개이면 0으로 정한다.

#### Odd Parity(홀수 패리티)

 홀수 패리티는 전체 비트에서 1의 개수가 홀수가 되도록 패리티 비트를 정하는 방법이다. 1의 개수가 홀수개이면 0, 짝수개이면 1이 된다.

#### 특징

 데이터를 송수신하는 과정에서 각 비트를 단위시간당 하나씩 보내게 되어있는데, 이 때 알수없는 요인에 의해서 비트의 값이 틀어져 1이 0으로 바뀌거나 0이 1로 바뀌었을 때 이를 확인할 수 있다.

 다만 오류 발생 여부를 알 수 있지 오류 수정을 할 수 있다는 것은 아니다. 데이터 손실을 인지하고, 수신 호스트에서 송신 호스트로 재전송 요청을 할 수 있도록 보다 안정적인 통신을 제공하는 수단이다.

 보통은 Checksum을 이용하고, 패리티 비트는 통신의 거리가 상당히 멀 경우에 주로 적용된다.

## OS

### Paging

 ![img](https://lh5.googleusercontent.com/PCKovkDHBKjR-f26p8W5580EgY2MlxvNdlNFdegkT5_h9JKFY5HMjHV8kfXhIjUFBDKCXqFYHbhP_oZJldJczeg_4rPpVPVIh0kzstq4NdZg3EUT1iwl22np7Ww11BcLsv-z-HOO)       

 논리적 메모리를 일정한 크기로 잘라서 물리적 메모리에 넣는것. 페이지 테이블에는 해당 페이지가 물리적 주소의 어디에 저장되어 있는지 저장해놓음. 0번 page는 1번 frame에 올라가있고, 1번은 4번에 저장되어있다. cpu가 논리적인 주소를 원하면 논리적인 주소로 바꿔야 하는데, 페이지 테이블로 찾는다. 주소에서 앞부분이 페이지 번호 뒤에 offset 논리적인 주소를 물리적인 주소로 찾아서 offset을 더해(위에서 몇번째인지) 물리적 주소를 반환한다. offset은 물리 논리 상관없이 같음. 

 페이지 테이블은 어디에 들어가는가. MMU는 레지스터로 처리하면 됐음. 프로그램 하나의 주소공간이 100만개의 page를 가지고 있는 pagetable이 있을것. 프로그램마다 page table이 필요하니까 비효율. 이게 어디에 들어가야 할까. page table을 메모리에 넣는다. 결국에는 메모리 접근을 위해서는 2번의 memory access 필요.  MMU는 page table base register와 page table length register로 사용된다. 주소변환을 위한 페이지 테이블의 크기와 테이블을 가리킴. 속도 향상을 위해 TLB를 추가. 별도의 하드웨어. 캐시라고 생각하면 편안. TLB에 저장되어 있는 정보 중에 내가 원하는 Page 정보가 있니 먼저 확인하고 있으면 메모리 접근(메모리 한번). 없으면 페이지 테이블 참고(메모리 2번) 

 TLB는 모든 페이지 정보가 있는 것이 아님. 그리고 논리적 페이지, 물리적 페이지 쌍을 모두 가지고 있어야 함. 있는지 확인하려면 전체 서치해야함. 그렇게 하지 않기 위해서 병렬 처리가 가능하도록 함. 한방에 쫙 서치해서. 페이지 내용 없는 경우를 미스라고함. 미스나면 페이지 테이블 볼 수 밖에.. 프로세스마다 주소 정보가 다르기 때문에 context switching이 발생할 때마다 내용을 바꿔야함. 

### CPU Scheduling

 CPU Scheduler 운영체제 안에서 스케줄링을 하는 코드임. 소프트웨어이다. Dispatcher도 역시 소프트웨어. dispatcher는 cpu를 누구에게 줄지 정했으면 실제로 cpu를 주는 역할을 하는 소프트웨어임. 이 과정을 context switch라고 함. 문맥교환.

#### CPU 스케줄링이 필요한 경우 

1. cpu를 어떤 프로세스가 가지고 있다가 io 작업처럼 오래 걸리는 작업을 하는 경우 자진해서 cpu를 내어주는 경우( Running -> Blocked)
2. 나는 더 쓰고 싶은데 운영체제가 강제로 빼앗는 경우 ( Running -> Ready )
3. IO를 요청하는 프로세스의 io 작업이 끝날경우. 인터럽트를 걸어 원래 실행되고 있는 프로세스가 잠시 중단된다. 인터럽트가 끝난 후 원래 실행되는 코드는 다시 실행되고 blocked됐던 프로세스는 ready로 변함. (Blocked -> Ready ) 
4. 프로세스가 종료되서 새로운 프로세스에 cpu를 넘기는 경우(Terminate)

 1,4의 경우 더이상 쓸 필요가 없어서 cpu 자진 반납. (nonpreemptive : 강제로 빼앗지 않고 자진 반납)
 2,3의 경우는 Preemptive(강제로 빼앗음)

#### CPU 스케줄러을 통한 성능 측정(성능 척도)

##### 시스템 입장에서의 성능 척도 : 최대한 많이 처리하는 것이 좋은것

- cpu utilization : 전체 시간 중에서 cpu를 이용한 비율. cpu를 놀리지 말고 최대한 일을 시켜라.
- Throughput(처리량) : 일정 시간 이내에 몇개의 일을 처리했느냐. 

##### 프로그램 입장에서의 성능 척도  : 내가 cpu빨리 얻어서 빨리 끝나는 것.

- Turnaround time(소요시간) : cpu를 쓰러 들어와서 다 쓸 때 까지 걸린 시간. 쓴 시간 + 기다린 시간 다 합친거.
- waiting time : cpu를 순수하게 기다린 시간 cpu를 얻었다가 뺐겼을 때, 기다리는 시간이 있을 것이다. 여러번 그럴것인데 기다린 모든 시간의 합.
- response time(응답시간) : ready queue에 들어와서 처음으로 cpu를 얻기까지 걸린 시간.

#### scheduling algorithm

##### FCFS

 먼저온 순서대로 처리. 사람의 세계에서는 대개 쓰는 방법. 효율적이지 않음.   convoy effect : 먼저온 프로세스가 너무 오랜시간 cpu를 사용해 뒤의 프로세스가 cpu를 빨리 사용하지 못하는 현상.

##### Shortest Job-First(SJF)

 빨리 끝나는 프로세스 먼저 cpu 쓰게 하는 알고리즘. Average waiting time을 최소화 할 수 있음. Preemptive한 상황에서는 (Shortest Remaining Time First)으로 최적의 Average waiting time을 얻을 수 있음.Non-Preemptive 한 경우, 긴 프로세스가 먼저 올 경우, 늦게 온 짧은 프로세스는 이를 계속 기다려야 함. 오래걸릴 수 있음. cpu를 다 쓰고 나가는 시점에 스케줄링이 일어난다.Preemptive한 경우 : 프로세스가 올 때마다 더 짧은 프로세스 먼저 쓰게 됨. 

 문제점 1. : Starvation. 극단적으로 cpu 사용이 짧은 것을 선호함. cpu 사용시간이 긴 프로세스는 영원히 사용하지 못할수도 있음.   
 문제점 2. cpu를 얼마나 쓰고 나갈지 예측할 수 없다. cpu 사용시간을 미리 알 수 없지만 추정할 순 있음. io bound의 경우 cpu 사용시간이 짧고, cpu bound의 경우 cpu 사용시간이 기니까 어느정도 추정할 수 있음. exponential averaging

##### Priority Scheduling

 우선순위가 높은 것에 cpu를 주겠다.  

- preemptive : 우선순위가 높은 프로세스가 들어오면 뺏어서 주겠다.  
- non-preemptive : 일단 프로세스 먼저 종료하고 우선순위가 높은 프로세스를 실행하겠다.  

 sjp의 경우 cpu 사용시간이 우선순위가 될 것이다. 그러나 문제점이 있음. 컴퓨터 시스템에서는 효율성이 가장 중요한 것은 맞지만 한쪽에 차별을 너무 주면 안된다. 그래서 Aging 기법을 사용함.

##### Round Robin Scheduling

 선점형 스케줄링. cpu를 줄 때 할당시간을 세팅해서 주게된다. 이 시간이 끝나면 ready queue에 프로세스가 놓임. 응답시간이 빨라지는 것이 장점. 현재 queue에 n개의 프로세스가 있다면 cpu 사용시간 / n 의 시간동안에 적어도 cpu를 할당받을 수 있다. q(cpu 사용시간)이 너무 클경우, FCFS가 되고, 너무 작을 경우 문맥 교환 비용이 너무 들어서 비효율적이 된다.

##### Multilevel Queue

 계급이 있다. 높은 계급이 먼저 cpu 쓰고 그다음 계급의 큐가 쓰고 ~~- 우선순위가 높은 큐를 모두 처리해야 낮은 큐를 처리한다.- ready queue를 여러 개로 분할. interactive한 프로세스인지 batch(no human interaction) 프로세스인지. 전자는 RR, 후자는 FCFS.

##### Multilevel Feedback Queue

 프로세스가 다른 큐로 이동 가능. 큐의 기준. 승격, 강등의 기준 등이 필요함. - 보통 처음들어오는 프로세스는 우선순위 가장 높게. time quantum을 짧게 줌. 다음 큐에는 점점 길게줌. 그러다 FCFS. cpu 사용 시간이 긴 프로세스는 낮은 큐로 갔다가 쓰임. cpu 사용시간이 짧은 프로세스에 우선권을 줌. 빨리 끝나니까. 긴 프로세스는 점점 낮은 큐로 밀려남. 

##### Multiple-Processor Scheduling

 큐에 한줄로 세워서 각 프로세서가 알아서 꺼내가게 하는 방법.

 특정 cpu에 실행해야하는 프로세스가 있으면 잘 스케줄링해야함. 

 Load Sharing : 일부 프로세서에 job이 몰리지 않도록 적절히 부하를 공유. 

##### Real-Time Scheduling

 deadline이 있는 잡. 데드라인을 보장해줘야 함. cpu에서 데드라인 안에 처리 해야하는 것이 목표. 미리 스케줄링을 해서 데드라인 안에 제대로 동작하도록 하는. real time이 periodical 한 경우가 많음. 데드라인 보장이 중요.- hard real-time system, soft real-time computing

#### Thread Scheduling

 스레드를 구현하는 방식 : User level thread, Kernal Level Thread. 상황이 다르기 때문에 스케줄링 하는 방법도 다름. 

- Local scheduling : 사용자 프로세스가 직접 cpu 스케줄링함. 
- Global scheduling : 일반 프로세스와 마찬가지로 커널에서 스케줄링함.

#### Algorithm Evaluation

- Queueing model : 큐에 job들이 도착해서 쌓임. cpu 용량에 따라 처리하고 빠져나감. 단위시간당 처리량 등등
- Implementation & Measurement : 실제 실행해서 비교. 운영체제의 스케줄러와 내가 만든 스케줄러를 같이 돌려서 어느것이 좋은지 비교하는 것. 실측함.
- Simulation : 실제로 돌리는 것이 아니라 모의실험. 시뮬레이션 코드 짜서. 여러가지 예제를 돌림.

## Data Structure

## Computer Structure

### 부동소수점

![General floating point ko.svg](https://upload.wikimedia.org/wikipedia/commons/thumb/8/88/General_floating_point_ko.svg/500px-General_floating_point_ko.svg.png)

실제 컴퓨터에서는 보통 [이진법](https://ko.wikipedia.org/wiki/이진법)을 사용하여 다음과 같이 세 부분의 값으로 실수를 나타낸다.

- 부호부 (1비트) : 양수일 때는 0, 음수일 때는 1
- 지수부 (부호가 있는 정수, 7비트) : 제일 앞의 1비트는 부호를 정하고, 나머지 6비트로 표시
- 정규화된 가수부 (부호가 없는 정수, 24비트) : 제일 앞의 비트는 정규화되었으므로 1이다.

예를 들어, 십진수 21.8125를 정규화된 이진수로 나타낸다고 해보자. 소수점 위의 (21.)10=(10101)2이고, 소수점 아래 (0.8125)10=(11010)2이다. 즉 (21.8125)10=(10101.11010)2이며, 이를 정규화하면 0.1010111010×25이다. 지수의 5를 이진법으로 바꾸면 101이다. 따라서, 32비트 정규화된 부동소수점수로 나타낸다면 맨 앞 비트의 부호는 0(양)이고, 지수부 부호는 0(양)이며, 지수부 나머지 6개 비트는 000101, 가수부는 101011101000…이 된다. 이것을 결합하면 000001011010111010000000000000000가 된다.

### 십진법 소수 -> 이진법으로만들기

![img](http://ncc.phinf.naver.net/ncc02/2011/7/25/198/6-2.jpg)

### CPU Clock

## DB

### Transaction

 #### ACID

- Atomicity : 한 트랜잭션 낸 실행한 작업들은 하나의 작업으로 간주한다. 모두 성공 또는 실패되어야 한다.
- Consistency : 모든 트랜잭션은 일관성있는 db상태를 유지한다. 
- Isolation : 동시에 실행되는 트랜잭션들이 서로 영향을 미치지 않도록 격리해야 한다.
- Durability : 트랜잭션을 성공적으로 마치면 그 결과가 항상 저장되어야 한다.
- 이슈 : 격리성을 완벽히 보장하기 위해 트랜잭션을 순차적으로 실행하면 동시성 처리 이슈가 발생한다. 동시성을 높이기 위해 여러 트랜잭션을 병렬처리하게 되면 데이터의 무결성이 깨질 수 있다.

#### Isolation 관련 문제점

- Dirty Read : 한 트랜잭션이 데이터에 접근하여 A를 B로 변경하고 커밋을 하지 않았을 때, 다른 트랜잭션이 해당 데이터를 read하면 B를 읽게 될 것이다. 그런데 커밋하지 않고 종료하면 다른 트랜잭션의 데이터는 꼬인다.
- Non-Repeatable Read : 한 트랜잭션 내에서 같은 쿼리를 수행할 경우, 같은 결과를 반환해야 하는데, 트랜잭션 수행 중 다른 트랜잭션이 값을 수정하는 경우, 다른 결과를 반환하게 된다.
- Phantom Read : 다른 트랜잭션이 추가한 데이터를 읽고 있는데 걔가 롤백하면 나는 귀신을 읽고 있는것.

#### Transaction Isolation Level

 위와 같은 문제들 때문에 ANSI 표준에서 트랜잭션의 격리성과 동시 처리 성능 사이의 Trade-off를 두고 4단계 격리수준을 나누었다. 내려갈수록 격리 수준이 높아져서 격리성은 높아지지만 동시 처리 성능은 떨어진다.

##### Read Uncommitted

 한 트랜잭션에서 커밋하지 않은 데이터에 다른 트랜잭션이 접근할 수 있다. 즉, 커밋하지 않은 데이터를 읽을 수 있다. 이 수준은 위에서 언급한 모든 문제가 발생할 가능성이 있다. 대신 동시 처리 성능은 가장 높다.

##### Read Committed

 커밋이 완료된 데이터만 읽을 수 있다. Dirty Read가 발생할 여지는 없지만 동시 처리 성능은 Read Uncommitted보다 떨어진다. 또한 Non-Repeatable Read와 Phantom Read는 발생 가능하다. db는 보통 Read Committed를 디폴트 수준으로 지정한다.

##### Repeatable Read

 트랜잭션 내에서 한번 조회한 데이터를 반복해서 조회해도 같은 데이터가 조회된다. 트랜잭션이 시작되기 전에 커밋된 내용에 대해서만 조회할 수 있는 격리수준이다. 이는 개별 데이터 이슈인 Dirty Read나 Non-Repeatble Read는 발생하지 않지만, 결과 집합 자체가 달라지는 Phantom Read는 발생가능하다.

##### Serializable

 가장 엄격한 격리 수준. 읽기 작업에도 공유 잠금을 설정한다.



[^1]: https://m.blog.naver.com/sbd38/50191972929
[^2]: https://tobewiseys.tistory.com/72